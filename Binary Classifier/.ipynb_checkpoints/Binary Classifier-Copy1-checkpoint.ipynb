{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear Classifiers\n",
    "Jeremiah Pratt\n",
    "\n",
    "Due on a wednesday or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from tkinter import *\n",
    "from tkinter import ttk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Decided to write a function for generating noisy data to make it easier to change data parameters\n",
    "#Generates two classes of noisy data with n total samples, true probability truPi,\n",
    "#means mu1 and mu0. Assumed covariance matrix is an identity matrix times a constant for simplicity.\n",
    "def genData(n,truPi,mu1,mu0,s):\n",
    "    num1 = n * truPi                   #Number of C1 Samples\n",
    "    num0 = n - n* truPi                #Number of C0 Samples\n",
    "    \n",
    "    cov = np.multiply(np.eye(2),s)     #Covariance Matrix\n",
    "    \n",
    "    t1 = np.ones(int(num1))            \n",
    "    t0 = np.zeros(int(num0))\n",
    "    U1 = np.random.multivariate_normal(mu1,cov,int(num1))             #Generating Noisy Data\n",
    "    U0 = np.random.multivariate_normal(mu0,cov,int(num0))\n",
    "    \n",
    "    x1 = np.append(np.atleast_2d(t1),U1.T,axis=0)                     #Noisy data plus classifier number(t1 or t0)\n",
    "    x0 = np.append(np.atleast_2d(t0),U0.T,axis=0)\n",
    "    \n",
    "    data = np.append(x1,x0,axis=1)\n",
    "    data = np.random.permutation(data.T).T                            #Mixing up the sample order\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finds p(C1) and p(C0)\n",
    "def findPis(data):\n",
    "    \n",
    "    n = np.size(data,1)\n",
    "    n1 = int(np.sum(data[0,:]))\n",
    "    n0 = n - n1\n",
    "    \n",
    "    pi1 = n1/n\n",
    "    pi0 = n0/n\n",
    "    \n",
    "    return pi1, pi0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic sigmoid function because I'm lazy\n",
    "def logSig(a):\n",
    "    sig = 1/(1+np.exp(-a))\n",
    "    sig = np.squeeze(sig)\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#given input data matrix and output classifications, returns percent correctly classified.\n",
    "def checkResults(data,classified):\n",
    "    \n",
    "    n = np.size(data,1)\n",
    "    correct = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        if classified[i] == data[0,i]:\n",
    "            correct +=1\n",
    "        \n",
    "    percent = correct/n\n",
    "    \n",
    "    return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#design matrix\n",
    "def design(data):\n",
    "    \n",
    "    data = np.atleast_2d(data)\n",
    "    \n",
    "    phi = np.concatenate([np.atleast_2d(np.ones_like(data[0,:])), np.atleast_2d(data[1,:]), \n",
    "                          np.atleast_2d(data[2,:])],axis=0)\n",
    "    \n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Finds approximate averages for a binary data set, along with the weighted average of the two set's covariance matrices.\n",
    "def findMusAndCovs(data):\n",
    "\n",
    "    n = np.size(data,1)                             #Number of data points\n",
    "    n1 = int(np.sum(data[0,:]))                     #Number of points in c1\n",
    "    n0 = n - n1                                     #Number of points in c2\n",
    "    \n",
    "    x1 = np.multiply(data[0,:],data[1,:]) \n",
    "    y1 = np.multiply(data[0,:],data[2,:])\n",
    "    x0 = np.multiply((1-data[0,:]),data[1,:])\n",
    "    y0 = np.multiply((1-data[0,:]),data[2,:])\n",
    "    \n",
    "    mux1 = (1/n1)*np.sum(x1)\n",
    "    muy1 = (1/n1)*np.sum(y1)\n",
    "    mux0 = (1/n0)*np.sum(x0)\n",
    "    muy0 = (1/n0)*np.sum(y0)\n",
    "    \n",
    "    mu1 = [mux1, muy1]                              #Averages concatenated together\n",
    "    mu0 = [mux0, muy0]                              \n",
    "    \n",
    "    mu1ar = np.multiply(np.atleast_2d(mu1).T,np.ones([2,n1]))     #Long array of averages\n",
    "    mu0ar = np.multiply(np.atleast_2d(mu0).T,np.ones([2,n0]))\n",
    "    \n",
    "    full1 = [x1[np.nonzero(x1)],y1[np.nonzero(y1)]]               #Concatenating x's and y's together, removing zero values\n",
    "    full0 = [x0[np.nonzero(x0)],y0[np.nonzero(y0)]]\n",
    "    \n",
    "    dif1 = full1 + np.multiply(mu1ar,-1)\n",
    "    dif0 = full0 + np.multiply(mu0ar,-1)\n",
    "    \n",
    "    s1 = (1/n1) * (dif1 @ dif1.T)\n",
    "    s0 = (1/n0) * (dif0 @ dif0.T)\n",
    "    \n",
    "    s = np.multiply(n1/n,s1) + np.multiply(n0/n,s0)\n",
    "    \n",
    "    return mu1,mu0,s,full1,full0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates alpha value for Gaussian logistic sigmoid\n",
    "def alphaGauss(x,mu1,mu0,s,pi1,pi0):\n",
    "    px1 = multivariate_normal.pdf(x,mu1,s)\n",
    "    px0 = multivariate_normal.pdf(x,mu0,s)\n",
    "    \n",
    "    alpha = np.log((px1*pi1)/(px0*pi0))\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Given testing data and two estimated averages, classify the testing data\n",
    "def classifyGauss(data,mu1,mu0,s):\n",
    "    \n",
    "    n = np.size(data,1)\n",
    "    pi1,pi0 = findPis(data)\n",
    "    \n",
    "    classified = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        a = alphaGauss(data[1:3,i],mu1,mu0,s,pi1,pi0)\n",
    "        sig = logSig(a)\n",
    "        if sig>0.5:\n",
    "            classified[i] = 1\n",
    "\n",
    "    \n",
    "    return classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRLS Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generates alpha value for IRLS\n",
    "def alphaIRLS(w,data):\n",
    "    w = np.atleast_2d(w)\n",
    "    data = np.atleast_2d(data)\n",
    "    #print(np.shape(w))\n",
    "    #print(np.shape(data))\n",
    "    alpha = np.squeeze(w @ data.T)\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Updating for IRLS weight vector\n",
    "def iterate(data):\n",
    "    n = np.size(data,1)\n",
    "    wOld = np.array([1, 1, 1])\n",
    "    R = np.zeros([n,n])\n",
    "    phi = design(data)\n",
    "    for i in range(20):                                  #We will iteratively update 20 times\n",
    "        wOld = np.atleast_2d(wOld)\n",
    "        \n",
    "        for j in range(n):                               #Diagonal R Matrix\n",
    "            y = logSig(alphaIRLS(wOld,phi[:,j].T))\n",
    "            R[j,j] = y * (1 - y)\n",
    "        \n",
    "        z = np.subtract((phi.T @ wOld.T).T,\n",
    "            np.atleast_2d((np.linalg.inv(R)) @ (logSig(alphaIRLS(wOld,phi.T)) - (data[0,:]))))\n",
    "        \n",
    "        wOld = np.linalg.inv(phi @ R @ phi.T) @ phi @ R @ z.T\n",
    "        \n",
    "        wOld = np.squeeze(wOld.T)\n",
    "\n",
    "    return wOld\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Classifying with IRLS\n",
    "def classifyIRLS(data,w):\n",
    "    \n",
    "    n = np.size(data,1)\n",
    "    classified = np.zeros(n)\n",
    "    \n",
    "    phi = design(data)\n",
    "    \n",
    "    for i in range(n):\n",
    "        a = alphaIRLS(w,phi[:,i].T)\n",
    "        sig = logSig(a)\n",
    "        if sig>0.5:\n",
    "            classified[i] = 1\n",
    "    \n",
    "    return classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main, let's bring everything together!!!\n",
    "numSamps = 100\n",
    "avg1 = [1,1]\n",
    "avg0 = [-1,-1]\n",
    "truPi = 0.5\n",
    "cov = 1\n",
    "\n",
    "trainingData = genData(numSamps,truPi,avg1,avg0,cov)\n",
    "testingData = genData(numSamps,truPi,avg1,avg0,cov)\n",
    "\n",
    "mu1,mu0,s,full1,full0 = findMusAndCovs(trainingData)\n",
    "pi1, pi0 = findPis(trainingData)\n",
    "\n",
    "gaussClassified = classifyGauss(testingData,mu1,mu0,s)\n",
    "\n",
    "percentGauss = checkResults(testingData,gaussClassified)\n",
    "\n",
    "w = iterate(trainingData)\n",
    "IRLSClassified = classifyIRLS(testingData,w)\n",
    "\n",
    "percentIRLS = checkResults(testingData,IRLSClassified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percent correct classification from Gaussian Generative Model is:\n",
      "0.91\n",
      "percent correct classification from IRLS Model is:\n",
      "0.93\n"
     ]
    }
   ],
   "source": [
    "print('percent correct classification from Gaussian Generative Model is:')\n",
    "print(percentGauss)\n",
    "print('percent correct classification from IRLS Model is:')\n",
    "print(percentIRLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Decision Boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scatter plots the points\n",
    "def plotPoints(data, ax):\n",
    "    \n",
    "    x1 = np.multiply(data[0,:],data[1,:]) \n",
    "    y1 = np.multiply(data[0,:],data[2,:])\n",
    "    x0 = np.multiply((1-data[0,:]),data[1,:])\n",
    "    y0 = np.multiply((1-data[0,:]),data[2,:])\n",
    "    \n",
    "    full1 = [x1[np.nonzero(x1)],y1[np.nonzero(y1)]]               #Concatenating x's and y's together, removing zero values\n",
    "    full0 = [x0[np.nonzero(x0)],y0[np.nonzero(y0)]]\n",
    "    ax.set_xlim([-3,3])\n",
    "    ax.set_ylim([-3,3])\n",
    "    ax.scatter(full1[0],full1[1],color='red')\n",
    "    ax.scatter(full0[0],full0[1],color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plotting decision boundary for Gaussian whatevertf\n",
    "def plotDecGauss(mu1,mu0,pi1,pi0,s,ax):\n",
    "    \n",
    "    mu1 = np.atleast_2d(mu1)\n",
    "    mu0 = np.atleast_2d(mu0)\n",
    "    \n",
    "    w = np.linalg.inv(s) @ (mu1 - mu0).T\n",
    "    w0 = -0.5 * mu1 @ np.linalg.inv(s) @ mu1.T + \\\n",
    "          0.5 * mu0 @ np.linalg.inv(s) @ mu0.T + \\\n",
    "          np.log(pi1/pi0)\n",
    "    \n",
    "    x = np.linspace(-3,3)\n",
    "    y = -(w[0]*x + w0)/w[1]\n",
    "    ax.plot(x,y.T,color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting decision boundary for logistinc regression\n",
    "def plotDecLinreg(w,ax):\n",
    "    \n",
    "    w = np.squeeze(w)\n",
    "    x = np.linspace(-3,3)\n",
    "    y = -(w[0] + (w[1]*x))/w[2]\n",
    "    ax.plot(x,y,color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure, axr = plt.subplots(nrows=1, ncols=2, figsize=[16,8])\n",
    "\n",
    "axr[0].set_title('Decision Boundary for Gaussian Generative Model')\n",
    "axr[1].set_title('Decision Boundary for IRLS Model')\n",
    "\n",
    "plotPoints(testingData,axr[0])\n",
    "plotPoints(testingData,axr[1])\n",
    "\n",
    "plotDecGauss(mu1,mu0,pi1,pi0,s,axr[0])\n",
    "plotDecLinreg(w,axr[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
